{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Data:  60000\n",
      "Number of Test Data:  10000\n",
      "Number of class:  10\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "\n",
    "nclass = 10\n",
    "ntrain = len(x_train)\n",
    "ntest = len(x_test)\n",
    "\n",
    "x_train = x_train/255.0\n",
    "x_train = np.reshape(x_train, (ntrain, -1))\n",
    "x_test = x_test/255.0\n",
    "x_test = np.reshape(x_test, (ntest, -1))\n",
    "\n",
    "labels = np.zeros((ntrain, nclass))\n",
    "labels[np.arange(ntrain), y_train] = 1\n",
    "y_train = labels\n",
    "\n",
    "labels = np.zeros((ntest, nclass))\n",
    "labels[np.arange(ntest), y_test] = 1\n",
    "y_test = labels\n",
    "\n",
    "print(\"Number of Training Data: \", ntrain)\n",
    "print(\"Number of Test Data: \", ntest)\n",
    "print(\"Number of class: \", nclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14510\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = np.random.randint(ntrain)\n",
    "\n",
    "imgplot = plt.imshow(np.reshape(x_train[idx], (28,28)))\n",
    "print(idx)\n",
    "print(y_train[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8184\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = np.random.randint(ntest)\n",
    "\n",
    "imgplot1 = plt.imshow(np.reshape(x_test[idx], (28,28)))\n",
    "print(idx)\n",
    "print(y_test[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "######Ouptut layer size determined by labeling function\n",
    "output_layer_size = nclass\n",
    "\n",
    "######Here is the neural net model described in Tensor Flow MNIST example\n",
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "x  = tf.placeholder(tf.float32, [None, 784], name='x')\n",
    "x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "y_ = tf.placeholder(tf.float32, [None, output_layer_size],  name='y_')\n",
    "\n",
    "# Convolutional layer 1\n",
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "# Convolutional layer 2\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "# Fully connected layer 1\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "# Dropout\n",
    "keep_prob  = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "# Fully connected layer 2 (Output layer)\n",
    "W_fc2 = weight_variable([1024, output_layer_size])\n",
    "b_fc2 = bias_variable([output_layer_size])\n",
    "\n",
    "y = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2, name='y')\n",
    "\n",
    "# Evaluation functions\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name='accuracy')\n",
    "\n",
    "# Training algorithm\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ranker_random(examples, sess=None):\n",
    "    return np.random.randint(10, size=len(examples))\n",
    "\n",
    "def ranker_max_min(examples, sess):\n",
    "    return [abs(np.max(s) - np.min(s)) for s in sess.run(y, feed_dict={x: examples, keep_prob: 1.0})]\n",
    "\n",
    "def ranker_best_second(examples, sess):\n",
    "    return [s[-1] - s[-2] for s in np.sort(sess.run(y, feed_dict={x: examples, keep_prob: 1.0}), axis=1)]\n",
    "\n",
    "def ranker_bayesian(examples, sess):\n",
    "    predicts = np.asarray([sess.run(y, feed_dict={x: examples, keep_prob: 0.5}) for i in range(15)])\n",
    "    var = np.var(predicts, axis=0)\n",
    "    var_sum = np.sum(var, axis=1)\n",
    "    return var_sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: rename batch_size, return np array instead of list\n",
    "\n",
    "###### Ranks mnist training images according to a rank function (random for normal, \n",
    "###### model evaluation for active learning)\n",
    "def choose_examples(datas = x_train, remain = [], batch_size = 50, ranker = ranker_random, chosen = [], sess = None):\n",
    "\n",
    "    #do not look at examples that have already been seen\n",
    "    lookup_index = range(0, ntrain)\n",
    "    look_size = min(batch_size * 30, len(remain))\n",
    "    random_draw = random.sample(range(len(remain)), look_size)\n",
    "\n",
    "    #rank the examples according to the rank function\n",
    "    remain_idx = remain[random_draw]\n",
    "    remain_data = datas[remain_idx]\n",
    "    remain = np.delete(remain, idx)\n",
    "    ranks = ranker(remain_data, sess)\n",
    "    scores = np.column_stack((remain_idx, ranks))\n",
    "    sort = scores[np.argsort(scores[:,1])]\n",
    "\n",
    "    #select examples based on their scores. we only pick the first {batch_size}th of data\n",
    "    batch_size = min(batch_size, len(scores))\n",
    "    selected = sort[:batch_size, 0]\n",
    "    return [selected.astype(int).tolist(), remain]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "######trains one model on a subset of mnist data for a certian number of epochs\n",
    "def epoch_sample(chosen, batch_size, epochs, sess):\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    runs = int(len(chosen) / batch_size)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        random.shuffle(chosen)\n",
    "        \n",
    "        for i in range(runs):\n",
    "            end = min((i + 1) * batch_size, len(chosen)-1)\n",
    "            batch_idx = chosen[i * batch_size: end]\n",
    "            training_data = x_train[batch_idx]\n",
    "            training_labels = y_train[batch_idx]\n",
    "            sess.run(train_step, feed_dict={x: training_data, y_: training_labels, keep_prob: 0.5})\n",
    "\n",
    "    [epoch_acc, epoch_ce] = sess.run([accuracy, cross_entropy], feed_dict={x: x_test, y_: y_test, keep_prob: 1.0})\n",
    "    print(\"Labels: \", len(chosen), \" Epochs: \", epochs, \" Acc: \", epoch_acc, \" Cross Entropy: \", epoch_ce)\n",
    "    \n",
    "    return [epoch_acc, epoch_ce]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_batch(size, max_steps, ranker, print_every):\n",
    "    #run_log = []\n",
    "    #batch_log = []\n",
    "    chosen = []\n",
    "    remain = np.arange(ntrain)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        print(\"Select Active Learning Dataset\")\n",
    "        timer1 = 0\n",
    "        timer2 = 0\n",
    "        for step in range(max_steps):\n",
    "            \n",
    "            start_time = time.time()\n",
    "            #if re-sampling turned on, will double size of the mini-batch\n",
    "            #by randomly sampling from previously trained on exmaples\n",
    "            next_batch, remain = choose_examples(x_train, remain, size, ranker, chosen, sess)\n",
    "            chosen = chosen + next_batch\n",
    "            if len(remain) <= 0:\n",
    "                remain = np.arange(ntrain)\n",
    "\n",
    "            batch_xs = x_train[next_batch]\n",
    "            batch_ys = y_train[next_batch]\n",
    "            end_time = time.time()\n",
    "            timer1 = timer1 + end_time - start_time\n",
    "\n",
    "            #Train the model using the mini-batch\n",
    "            start_time = time.time()\n",
    "            sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys, keep_prob: 0.5})\n",
    "\n",
    "            if (step % print_every) == 0:\n",
    "                [acc, ce] = sess.run([accuracy, cross_entropy], feed_dict={x: x_test, y_: y_test, keep_prob: 1.0})\n",
    "#                 print(acc)\n",
    "#                 run_log.append([step, acc, ce])\n",
    "            end_time = time.time()\n",
    "            timer2 = timer2 + end_time - start_time\n",
    "\n",
    "        print(timer1)\n",
    "        print(timer2)\n",
    "        [final, final_ce] = sess.run([accuracy, cross_entropy], feed_dict={x: x_test, y_: y_test, keep_prob: 1.0})\n",
    "        #run_log.append([max_steps, final, final_ce])\n",
    "        #batch_log.append(run_log)\n",
    "\n",
    "        #start multi-epoch portion (kind of pasted on at the end)\n",
    "        epoch_logs = []\n",
    "        label_range = 250\n",
    "        epochs = 20\n",
    "        epoch_batch_size = 50\n",
    "        iteration = 20\n",
    "\n",
    "        print(\"\\nStart Training the Network with the selected Dataset\")\n",
    "        start_time = time.time()\n",
    "        #for label_size in range(iteration):\n",
    "        labels_length = (iteration + 1) * label_range\n",
    "        result = epoch_sample(chosen[0: labels_length], epoch_batch_size, epochs, sess)\n",
    "        end_time = time.time()\n",
    "        print(end_time - start_time)\n",
    "        #epoch_logs.append([labels_length, epochs, result[0], result[1]])\n",
    "\n",
    "#         print(\"labels\\tepoch\\taccuracy\\tcross entropy\")\n",
    "#         for entry in epoch_logs:\n",
    "#             print(entry[0], \"\\t\", entry[1], \"\\t\", entry[2], \"\\t\", entry[3])\n",
    "    print(\"\\nFinish Training\")\n",
    "    #return batch_log\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def print_average_series(to_average, columns, column_names):\n",
    "#    labels = [int(a[0]) for a in to_average[0]]\n",
    "#   column_collection = []\n",
    "#   for column in columns:\n",
    "#         transformed = []\n",
    "#         for run in to_average:\n",
    "#             transformed.append([a[column] for a in run])\n",
    "#         column_collection.append(np.mean(np.transpose(transformed), axis=1))\n",
    "#     column_collection.insert(0, np.array(labels))\n",
    "#     column_names.insert(0, 'iteration')\n",
    "#     print(*column_names, sep='\\t')\n",
    "#     for row in np.transpose(column_collection):\n",
    "#         print(*row, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select Active Learning Dataset\n",
      "12.888977766036987\n",
      "8.751887321472168\n",
      "\n",
      "Start Training the Network with the selected Dataset\n",
      "Labels:  5250  Epochs:  20  Acc:  0.9823  Cross Entropy:  0.05678132\n",
      "18.22598361968994\n",
      "\n",
      "Finish Training\n",
      "40.842612743377686\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "iterations = 1000\n",
    "print_every = 100\n",
    "ranker = ranker_best_second\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "results = run_batch(batch_size, iterations, ranker, print_every)\n",
    "#pint_average_series(results, [1, 2], [\"accuracy\", \"cross entropy\"])\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "print(end_time - start_time)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
